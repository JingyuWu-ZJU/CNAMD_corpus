The Chinese Natural Audiovisual Multi-modal Database (CNAMD) corpus is the first and largest freely available Chinese multi-modal database in multi-person interaction.


It contains over 50 hours of videos and eight different modals' annotation, including: vocal-verbal, audio, head movement, eyebrow, handedness, handmovement, general face and body posture.

We given the sample of our corpus in this url:
https://pan.baidu.com/s/1VezJsVoukTCFnG9irVsp1Q  
pwd:72fi

The full corpus will be released and freely available soon.

